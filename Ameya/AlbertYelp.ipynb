{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from transformers import  BertTokenizer, TFAlbertModel\n",
    "import implicit\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "numpyArray = np.load('../Jiro/features.npy')\n",
    "np.load = np_load_old\n",
    "ratings_ = df = pd.DataFrame(numpyArray, columns = ['user_id','business_id','stars','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    user_id             business_id stars  \\\n",
      "0    mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   3.0   \n",
      "1    OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   5.0   \n",
      "2    8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   3.0   \n",
      "3    _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   5.0   \n",
      "4    bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   4.0   \n",
      "..                      ...                     ...   ...   \n",
      "995  syyKcKPFILDysHWmtka-aA  1_hDCN3iioFR3XnUr32ZtA   5.0   \n",
      "996  _lgLNzpzf3qmbwySBakxEw  5RzJ2bjU8bLSaN5SuiUpYA   4.0   \n",
      "997  Sh_vUlHHY2Kuj14eF8NYZQ  s1PNBO9o5jIgNd5YWUDLXQ   5.0   \n",
      "998  YwMD-AVT67fmYRGxnlRSPA  alUk6OwNhofyc90NDMDY-Q   5.0   \n",
      "999  WKe2b_EeLBnZ3lZV5WKYGQ  -Or44IdY51Ukd618kikmtA   4.0   \n",
      "\n",
      "                                                  text  \n",
      "0    [CLS] If you decide to eat here , just be awar...  \n",
      "1    [CLS] I ' ve taken a lot of spin classes over ...  \n",
      "2    [CLS] Family diner . Had the b ##uff ##et . E ...  \n",
      "3    [CLS] Wow ! Yu ##mmy , different , delicious ....  \n",
      "4    [CLS] Cut ##e interior and owner ( ? ) gave us...  \n",
      "..                                                 ...  \n",
      "995  [CLS] I Recently vacation ##ed in St . Petersb...  \n",
      "996  [CLS] Very cool bar attached to the Alexander ...  \n",
      "997  [CLS] This hotel is a g ##em in the heart of P...  \n",
      "998  [CLS] Was taken here today by a Colombian frie...  \n",
      "999  [CLS] My friends and I all got one of each tha...  \n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apran\\AppData\\Local\\Temp\\ipykernel_9432\\158573555.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratingsnew['text'] = ratingsnew['text'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "ratingsnew = ratings_.head(5000)\n",
    "# ratingsnew[\"stars\"].astype(float).round()\n",
    "\n",
    "for count in range(len(ratingsnew.text)):\n",
    "    ratingsnew.at[count, 'text'] = \" \".join(ratingsnew.at[count, 'text'])\n",
    "\n",
    "ratingsnew['text'] = ratingsnew['text'].astype(str)\n",
    "print(ratings_.head(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apran\\AppData\\Local\\Temp\\ipykernel_9432\\1422376793.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_features[\"user_id\"]  = df_features['user_id'].astype(\"category\").cat.codes\n",
      "C:\\Users\\apran\\AppData\\Local\\Temp\\ipykernel_9432\\1422376793.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_features[\"business_id\"]  = df_features['business_id'].astype(\"category\").cat.codes\n"
     ]
    }
   ],
   "source": [
    "# df_features = df_ratings.pivot_table(\n",
    "#     index = \"user_id\",\n",
    "#     columns = \"business_id\",\n",
    "#     values = \"labels\",\n",
    "# ).fillna(0)\n",
    "df_features = ratingsnew\n",
    "df_features[\"user_id\"]  = df_features['user_id'].astype(\"category\").cat.codes\n",
    "df_features[\"business_id\"]  = df_features['business_id'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sparse_item_user = sparse.csr_matrix((df_features['stars'].astype('float'), (df_features['user_id'], df_features['business_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((df_features['stars'].astype('float'),  (df_features['business_id'],df_features['user_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apran\\anaconda3\\envs\\nlp\\lib\\site-packages\\implicit\\utils.py:33: UserWarning: Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deea494c1f414fd6977b65d981bfa9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelRec = implicit.als.AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20)\n",
    "\n",
    "\n",
    "alpha_val = 40\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "\n",
    "\n",
    "modelRec.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apran\\AppData\\Local\\Temp\\ipykernel_9432\\3483575756.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_features[\"labels\"] = df_features.apply(lambda row: modelRec.user_factors[row['user_id']],axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3819</td>\n",
       "      <td>1410</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[CLS] If you decide to eat here , just be awar...</td>\n",
       "      <td>[0.83281374, 1.2656626, 0.6399664, 0.33444056,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986</td>\n",
       "      <td>364</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[CLS] I ' ve taken a lot of spin classes over ...</td>\n",
       "      <td>[-0.5846839, 0.57967913, -0.9137627, 1.3546611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703</td>\n",
       "      <td>1462</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[CLS] Family diner . Had the b ##uff ##et . E ...</td>\n",
       "      <td>[-0.5906147, 1.0514983, -0.07299996, -0.365408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2803</td>\n",
       "      <td>2042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[CLS] Wow ! Yu ##mmy , different , delicious ....</td>\n",
       "      <td>[-0.2597068, 1.1857792, -0.12551075, 0.3440103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005</td>\n",
       "      <td>1732</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[CLS] Cut ##e interior and owner ( ? ) gave us...</td>\n",
       "      <td>[0.9673988, -0.28625256, 1.442116, -0.19857486...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  business_id stars  \\\n",
       "0     3819         1410   3.0   \n",
       "1     1986          364   5.0   \n",
       "2      703         1462   3.0   \n",
       "3     2803         2042   5.0   \n",
       "4     3005         1732   4.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  [CLS] If you decide to eat here , just be awar...   \n",
       "1  [CLS] I ' ve taken a lot of spin classes over ...   \n",
       "2  [CLS] Family diner . Had the b ##uff ##et . E ...   \n",
       "3  [CLS] Wow ! Yu ##mmy , different , delicious ....   \n",
       "4  [CLS] Cut ##e interior and owner ( ? ) gave us...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0.83281374, 1.2656626, 0.6399664, 0.33444056,...  \n",
       "1  [-0.5846839, 0.57967913, -0.9137627, 1.3546611...  \n",
       "2  [-0.5906147, 1.0514983, -0.07299996, -0.365408...  \n",
       "3  [-0.2597068, 1.1857792, -0.12551075, 0.3440103...  \n",
       "4  [0.9673988, -0.28625256, 1.442116, -0.19857486...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features[\"labels\"] = df_features.apply(lambda row: modelRec.user_factors[row['user_id']],axis=1)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9432\\198374112.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stars\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stars\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\apran\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\apran\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df_features, test_size = 0.2)\n",
    "# y_train = tf.convert_to_tensor(\n",
    "#     train_df[\"labels\"].tolist(), dtype=float\n",
    "# )\n",
    "\n",
    "# y_test = tf.convert_to_tensor(\n",
    "#     test_df[\"labels\"].tolist(), dtype=float\n",
    "# )\n",
    "\n",
    "y_train = tf.convert_to_tensor(train_df[\"stars\"],dtype = \"float\")\n",
    "y_test = tf.convert_to_tensor(test_df[\"stars\"],dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type albert. This is not supported for all configurations of models and can yield errors.\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFAlbertModel: ['lm_head', 'roberta']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFAlbertModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['albert']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "albert = TFAlbertModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer(\n",
    "    text=train_df.text.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "x_test = tokenizer(\n",
    "    text=test_df.text.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = x_train['input_ids']\n",
    "attention_mask = x_train['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = albert(input_ids,attention_mask = input_mask)[0] \n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "y = Dense(1,activation = 'linear')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=5e-05, \n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "# Set loss and metrics\n",
    "loss = MeanSquaredError()\n",
    "metric = MeanSquaredError()\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = [MeanSquaredError(),MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 205s 2s/step - loss: 10.8597 - mean_squared_error: 10.8628 - mean_absolute_percentage_error: 70.6145 - val_loss: 9.8341 - val_mean_squared_error: 9.8371 - val_mean_absolute_percentage_error: 66.2656\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "logdir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = y_train,\n",
    "    validation_data = (\n",
    "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
    "    ),\n",
    "  epochs=1,\n",
    "    batch_size=36\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 47s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.07338618, -0.16550851,  0.19762458,  0.13882157,  0.70970327,\n",
       "        0.1453692 , -0.12702344, -0.22565615,  0.33704442,  0.09919152,\n",
       "       -0.07618295,  0.4068375 ,  0.7313061 ,  0.17470661, -0.0462678 ,\n",
       "        0.6731024 , -0.34431297,  0.5557975 , -0.08950389,  0.49181062,\n",
       "        0.09133173,  0.1401916 ,  0.43573844,  0.01401897,  0.5454296 ,\n",
       "       -0.18015033,  0.00132966,  0.24726276,  0.3089882 , -0.06192656,\n",
       "        0.3238145 ,  0.23126423,  0.46009997,  0.07715008,  0.1180399 ,\n",
       "        0.41326857,  0.11875076, -0.03306757,  0.11249358, -0.00437386,\n",
       "       -0.19619341,  0.25593755,  0.12059343,  0.26493603, -0.14641486,\n",
       "        0.50326216,  0.01874345,  0.12550904,  0.28127506,  0.13327202],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_raw = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
    "predicted_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'balanced_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31112\\3019641790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'balanced_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_balanced_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'balanced_accuracy'"
     ]
    }
   ],
   "source": [
    "plt.plot(train_history.history['balanced_accuracy'])\n",
    "plt.plot(train_history.history['val_balanced_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2475\n"
     ]
    }
   ],
   "source": [
    "user_id = test_df['user_id'].tolist()[0]\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07338618 -0.16550851  0.19762458  0.13882157  0.70970327  0.1453692\n",
      " -0.12702344 -0.22565615  0.33704442  0.09919152 -0.07618295  0.4068375\n",
      "  0.7313061   0.17470661 -0.0462678   0.6731024  -0.34431297  0.5557975\n",
      " -0.08950389  0.49181062  0.09133173  0.1401916   0.43573844  0.01401897\n",
      "  0.5454296  -0.18015033  0.00132966  0.24726276  0.3089882  -0.06192656\n",
      "  0.3238145   0.23126423  0.46009997  0.07715008  0.1180399   0.41326857\n",
      "  0.11875076 -0.03306757  0.11249358 -0.00437386 -0.19619341  0.25593755\n",
      "  0.12059343  0.26493603 -0.14641486  0.50326216  0.01874345  0.12550904\n",
      "  0.28127506  0.13327202]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.97298366,  0.44039735, -0.28015625, -0.7521654 , -0.4489915 ,\n",
       "        0.49497902,  0.9454965 ,  0.00147821,  0.5308483 ,  0.3728317 ,\n",
       "        0.52546084,  0.8189478 ,  1.007743  ,  1.1052285 ,  0.05325857,\n",
       "        0.0489132 , -0.43447438, -0.12374634, -0.00389834,  0.74936485,\n",
       "        0.28737143, -0.20584151, -0.70535696,  0.07942642,  0.97853667,\n",
       "        0.5248469 , -0.72075075, -0.5658454 , -0.39982104, -0.0266807 ,\n",
       "       -0.68635446, -0.6830612 ,  0.26648083, -0.73036444, -0.0186379 ,\n",
       "       -0.45450732, -0.6394246 ,  0.88162196, -0.00256596,  0.23782367,\n",
       "       -0.52691346, -0.70416456,  0.20566894,  1.0365378 ,  0.7459492 ,\n",
       "        0.14979783, -0.8075822 , -0.70098406,  0.35064295,  0.5860384 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newVector = np.array(predicted_raw[0])\n",
    "print(newVector)\n",
    "modelRec.user_factors[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2210, 1093,  966,  981, 1754, 1861, 1520, 1628, 2455, 1944, 2094,\n",
       "        2563, 1154,  343, 2170,  652, 1740,  469, 1185, 1918]),\n",
       " array([0.4837332 , 0.43117538, 0.3775813 , 0.36282626, 0.36107212,\n",
       "        0.3452233 , 0.32818776, 0.3239207 , 0.2970935 , 0.2922436 ,\n",
       "        0.29059905, 0.28478357, 0.2842365 , 0.28270864, 0.27976733,\n",
       "        0.278482  , 0.2759957 , 0.27330327, 0.27211142, 0.271969  ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRec.recommend(user_id,data_conf[user_id], N = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2166,  469, 1342,  872, 2613,  252, 2478,  171, 2084, 1810,  666,\n",
      "        518,  134, 1964,  756,  423,  465,  440,  630,  195, 1827, 2349,\n",
      "       1185, 2261, 1686,  555, 2491,  107, 1676,   40]), array([0.10468029, 0.09051982, 0.08740012, 0.08347838, 0.08332894,\n",
      "       0.08098835, 0.08068367, 0.07956488, 0.0774186 , 0.07591844,\n",
      "       0.07547419, 0.07518977, 0.07424901, 0.0727215 , 0.07023704,\n",
      "       0.06971195, 0.06905746, 0.06793718, 0.06787977, 0.0671107 ,\n",
      "       0.06567258, 0.06548437, 0.06544199, 0.06511699, 0.06510273,\n",
      "       0.06482379, 0.06472807, 0.06373616, 0.0632884 , 0.06257409],\n",
      "      dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "modelRec.user_factors[user_id] = newVector\n",
    "print(modelRec.recommend(user_id,data_conf[user_id], N =20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01e324c03c5ee44cfc350c404c36a95e3abce22ea98097e9b08ab515c12efc75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
